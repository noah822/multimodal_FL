{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class residual(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels,\n",
    "                 kernel_size, stride=1,\n",
    "                 use_1x1_conv=False):\n",
    "        super(residual, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, out_channels,\n",
    "                              kernel_size=3, padding=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = None\n",
    "        if use_1x1_conv:\n",
    "            self.conv3 = nn.Conv2d(input_channels, out_channels,\n",
    "                                   kernel_size=1, stride=stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        y = self.bn2(self.conv2(y))\n",
    "        \n",
    "        if self.conv3:\n",
    "            y += self.conv3(x)\n",
    "        else: y += x\n",
    "        \n",
    "        return F.relu(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class res_block(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, stride=1):\n",
    "            super(res_block, self).__init__()\n",
    "            use_1x1_conv = (input_channels != output_channels)\n",
    "            self.layer1 = residual(input_channels, output_channels,\n",
    "                                   kernel_size=3, stride=stride,\n",
    "                                   use_1x1_conv=use_1x1_conv)\n",
    "            \n",
    "            self.layer2 = residual(output_channels, output_channels,\n",
    "                                   kernel_size=3)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 8, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        \n",
    "        self.res_blk1 = res_block(8, 16, stride=2)\n",
    "        self.res_blk2 = res_block(16, out_channels, stride=2)\n",
    "        # self.res_blk3 = res_block(32, out_channels, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        x = self.res_blk1(x)\n",
    "        x = self.res_blk2(x)\n",
    "        # x = self.res_blk3(x)\n",
    "        return x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE_block(nn.Module):\n",
    "    def __init__(self, input_channels, reduce_ratio):\n",
    "        super(SE_block, self).__init__()\n",
    "        hidden_channels = input_channels // reduce_ratio\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_channels, hidden_channels)\n",
    "        self.fc2 = nn.Linear(hidden_channels, input_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        \n",
    "        squeezed_tensor = x.view(B, C, -1).mean(dim=2)\n",
    "        \n",
    "        Y = F.relu(self.fc1(squeezed_tensor))\n",
    "        Y = torch.sigmoid(self.fc2(Y))\n",
    "        \n",
    "        return torch.mul(x, Y.view(B, C, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_18(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (res_blk1): res_block(\n",
      "    (layer1): residual(\n",
      "      (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(8, 16, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (layer2): residual(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (res_blk2): res_block(\n",
      "    (layer1): residual(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
      "    )\n",
      "    (layer2): residual(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "AdaptiveAvgPool2d(output_size=32)\n",
      "Linear(in_features=32, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(ResNet_18(1, 32),\n",
    "                      nn.AdaptiveAvgPool2d(32),\n",
    "                      nn.Linear(32, 10))\n",
    "for layer in model:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MINIST dataset\n",
    "\n",
    "train_data =  torchvision.datasets.MNIST(\n",
    "    root = './MINIST/',\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.ToTensor(),\n",
    "    download = False\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = './MINIST/',\n",
    "    train = False,\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 7, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1141efa90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=3, shuffle=True)\n",
    "\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "img, label = next(data_iter)\n",
    "print(label)\n",
    "\n",
    "img = torchvision.utils.make_grid(img)\n",
    "\n",
    "plt.imshow(np.transpose(img.numpy(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_18 output shape:\t torch.Size([1, 32, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 32, 32, 32])\n",
      "Linear output shape:\t torch.Size([1, 32, 32, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand((1,1,28,28))\n",
    "for layer in model:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "    # print(layer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AVNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AVNet, self).__init__()\n",
    "        self.audio_net = ResNet_18(1, 32)\n",
    "        self.visual_net = ResNet_18(1, 32)\n",
    "        self.SE_layer = SE_block(64, 8)\n",
    "        self.ada_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, a, v):\n",
    "        a = self.audio_net(a)\n",
    "        v = self.visual_net(v)\n",
    "        \n",
    "        x = self.SE_layer(torch.concat([a, v], dim=1))\n",
    "        x = self.flatten(self.ada_pool(x))\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((1, 1, 28, 28))\n",
    "y = torch.rand((1, 1, 28, 28))\n",
    "model = AVNet()\n",
    "res = model(x, y)\n",
    "print(res.size())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
